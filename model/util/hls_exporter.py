'''
Author: Sandro Pedrett
History:
    - creation and written by Sandro Pedrett
    - 4.4.24 adjusted to ltc project by Yanik Kuster
'''

import datetime
import os
import numpy as np

from util.header_writer import HLSHeaderWriter, macrocase


def export_weights(layers: dict, output_path='./model_config.h', model_resolution: int=None):
    """
    Exports weights to a format suitable for Vitis HLS.
    positional arguments:
    - layers: A dictionary containing a dictionary for each layer with params to be exported: dict  e.g. {"dense1": {"weights": A, "biases": b, "bias_shifts": 3, "weight_shifts": 4}}
    - output_path: path to where params are exported to.
    - model_resolution: An integer that specifies the number of bits for used by the quantisation. If None is passes, then parameter are assumed to be non-quantized with type float.
    """

    # convert paths
    file_path, file_name = os.path.split(output_path)
    file_name, _ = os.path.splitext(file_name)
    os.makedirs(file_path, exist_ok=True)
    
    # typedef names
    model_resolution_name = macrocase("model_resolution")

    # write c/c++ header file
    with open(output_path, 'x') as file_stream:
        writer = HLSHeaderWriter(file_stream)

        writer.write_block_comment([
            f"Generated by {os.path.basename(__file__)} at {datetime.datetime.now().strftime('%d.%m.%Y, %H:%M:%S')}",
            f"",
            f"AUTO-GENERATED FILE. DO NOT MODIFY."
        ])

        writer.write_new_line()
        writer.write_preprocessor(f"ifndef {macrocase(file_name + '_h')}")
        writer.write_preprocessor(f"define {macrocase(file_name + '_h')}")
        writer.write_new_line()
        writer.write_preprocessor(f"include <cstddef>")
        writer.write_preprocessor(f"include <cstdint>")
        writer.write_preprocessor(f"include <ap_int.h>")
        writer.write_new_line()
        if model_resolution is not None:
            writer.write_constant(model_resolution_name, "size_t", model_resolution)
            writer.write_typedef(f"ap_int<{model_resolution_name}>", "modelData_t")
        else:
            writer.write_typedef(f"float", "modelData_t")

        for layer_name, layer in layers.items():
            writer.write_new_line()
            writer.write_block_comment(f"Layer: {layer_name}")

            for key in layer.keys():
                if "weights" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "modelData_t", layer[key])
                elif "biases" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "modelData_t", layer[key])
                elif "bias_shift" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])
                elif "weight_shift" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])
                elif "units" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "size_t", layer[key])
                elif "inFeatures" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "size_t", layer[key])
                elif "inputlayer" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "size_t", layer[key])
                elif "states" in key:
                    writer.write_buffer(macrocase(f"{layer_name}_{key}"), "modelData_t", layer[key])
                elif "_sw" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])
                elif "_sb" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])
                elif "_inScale" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])
                elif "_inStateScale" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])
                elif "_inSigScale" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])
                elif "_outNoActivationScale" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])
                elif "_out_activationScale" in key:
                    writer.write_constant(macrocase(f"{layer_name}_{key}"), "int", layer[key])

        writer.write_new_line()
        writer.write_preprocessor(f"endif")


if __name__ == '__main__':
    # test float model export
    neurons = 5
    A = np.linspace(-10, 10, neurons**2, dtype=float).reshape((neurons, neurons))*1e-6
    b = np.linspace(-10, 10, neurons, dtype=float).reshape((neurons, 1))

    params = {}
    params["weights"] = A
    params["biases"] = b

    layers = {}
    layer_name = "dense1"
    layers[layer_name] = params

    export_weights(layers, '../data/model_export/model_config_float.h')

    # test quant model export
    neurons = 5
    A = np.zeros((neurons, neurons), dtype=int)
    b = np.zeros((neurons, 1), dtype=int)

    params = {}
    params["weights"] = A
    params["biases"] = b
    params["weight_shift"] = 6
    params["bias_shift"] = 2

    layers = {}
    layer_name = "dense1"
    layers[layer_name] = params

    model_resolution = 8

    export_weights(layers, '../data/model_export/model_config_quant.h', model_resolution)
